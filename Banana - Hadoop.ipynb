{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b83d633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, Process\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f490aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 22:20:21.381736: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-17 22:20:21.979567: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-17 22:20:21.981576: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-17 22:20:23.704619: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7df94d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "648606da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, Using CPU.\n"
     ]
    }
   ],
   "source": [
    "if gpus:\n",
    "    print('GPU(s) available')\n",
    "    for gpu in gpus:\n",
    "        print(gpu)\n",
    "else:\n",
    "    print('No GPU available, Using CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0037c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54e1befb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 2\n"
     ]
    }
   ],
   "source": [
    "num_cpu_cores = multiprocessing.cpu_count()\n",
    "print(f'Number of CPU cores: {num_cpu_cores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b805e541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d078b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_devices =2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d70cf396",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '//home//hduser//Desktop//BANANAS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1862cb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height, img_width = 540, 960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cbcb7304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_name):\n",
    "    if file_name.startswith('g'):\n",
    "        return 1\n",
    "    elif file_name.startswith('Y'):\n",
    "        return 2\n",
    "    elif file_name.startswith('R'):\n",
    "        return 3\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dcdeb567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_path):\n",
    "    label = get_label(os.path.basename(image_path)[0])\n",
    "    \n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (img_width, img_height))\n",
    "    \n",
    "    img = img.astype('float32') /255.0\n",
    "    \n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f7796bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data, labels):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(16, (3,3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        layers.Conv2D(32, (3,3),activation = 'relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(32, activation ='relu'),\n",
    "        layers.Dense(3, activation ='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss = 'sparse_categorical_crossentropy',\n",
    "                 metrics =['accuracy'])\n",
    "    batch_size= 32\n",
    "    \n",
    "    \n",
    "    history = model.fit(data, labels, epochs =10, validation_split=0.2, batch_size = batch_size)\n",
    "    test_loss, test_acc = model.evaluate(date, labels, verbose = 2)\n",
    "    print('Test accuracy:', test_acc)\n",
    "    print('Test loss:', teest_loss)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97ff1725",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 22:58:29.169514: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 521662464 exceeds 10% of free system memory.\n",
      "2023-09-17 22:58:29.178398: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 521662464 exceeds 10% of free system memory.\n",
      "2023-09-17 22:58:32.462235: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 521662464 exceeds 10% of free system memory.\n",
      "2023-09-17 22:58:32.468610: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 521662464 exceeds 10% of free system memory.\n",
      "2023-09-17 22:58:33.839688: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 521662464 exceeds 10% of free system memory.\n",
      "2023-09-17 22:58:33.839675: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 521662464 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 22:58:46.069907: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 521662464 exceeds 10% of free system memory.\n",
      "2023-09-17 22:58:48.016277: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 521662464 exceeds 10% of free system memory.\n",
      "2023-09-17 22:58:50.551044: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at sparse_xent_op.cc:103 : INVALID_ARGUMENT: Received a label value of 3 which is outside the valid range of [0, 3).  Label values: 1 2 3 3 3 3 1 1 2 3 1 2\n",
      "Process Process-31:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_4103/2450215831.py\", line 17, in train_model\n",
      "    history = model.fit(data, labels, epochs =10, validation_split=0.2, batch_size = batch_size)\n",
      "  File \"/home/hduser/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/hduser/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:\n",
      "\n",
      "Detected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n",
      "    File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "      return _run_code(code, main_globals, None,\n",
      "    File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "      exec(code, run_globals)\n",
      "    File \"/usr/lib/python3/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "      app.launch_new_instance()\n",
      "    File \"/usr/lib/python3/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
      "      app.start()\n",
      "    File \"/usr/lib/python3/dist-packages/ipykernel/kernelapp.py\", line 677, in start\n",
      "      self.io_loop.start()\n",
      "    File \"/usr/lib/python3/dist-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "      self.asyncio_loop.run_forever()\n",
      "    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "      self._run_once()\n",
      "    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "      handle._run()\n",
      "    File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "      self._context.run(self._callback, *self._args)\n",
      "    File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 461, in dispatch_queue\n",
      "      await self.process_one()\n",
      "    File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 450, in process_one\n",
      "      await dispatch(*args)\n",
      "    File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 357, in dispatch_shell\n",
      "      await result\n",
      "    File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 652, in execute_request\n",
      "      reply_content = await reply_content\n",
      "    File \"/usr/lib/python3/dist-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n",
      "      res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "    File \"/usr/lib/python3/dist-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n",
      "      return super().run_cell(*args, **kwargs)\n",
      "    File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n",
      "      result = self._run_cell(\n",
      "    File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n",
      "      return runner(coro)\n",
      "    File \"/usr/lib/python3/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "      coro.send(None)\n",
      "    File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n",
      "      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "    File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "      if (await self.run_code(code, result,  async_=asy)):\n",
      "    File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n",
      "      exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"/tmp/ipykernel_4103/3373533575.py\", line 25, in <module>\n",
      "      process1.start()\n",
      "    File \"/usr/lib/python3.10/multiprocessing/process.py\", line 121, in start\n",
      "      self._popen = self._Popen(self)\n",
      "    File \"/usr/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen\n",
      "      return _default_context.get_context().Process._Popen(process_obj)\n",
      "    File \"/usr/lib/python3.10/multiprocessing/context.py\", line 281, in _Popen\n",
      "      return Popen(process_obj)\n",
      "    File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__\n",
      "      self._launch(process_obj)\n",
      "    File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 71, in _launch\n",
      "      code = process_obj._bootstrap(parent_sentinel=child_r)\n",
      "    File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "      self.run()\n",
      "    File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "      self._target(*self._args, **self._kwargs)\n",
      "    File \"/tmp/ipykernel_4103/2450215831.py\", line 17, in train_model\n",
      "      history = model.fit(data, labels, epochs =10, validation_split=0.2, batch_size = batch_size)\n",
      "    File \"/home/hduser/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/hduser/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1742, in fit\n",
      "      tmp_logs = self.train_function(iterator)\n",
      "    File \"/home/hduser/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1338, in train_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"/home/hduser/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1322, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"/home/hduser/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1303, in run_step\n",
      "      outputs = model.train_step(data)\n",
      "    File \"/home/hduser/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1081, in train_step\n",
      "      loss = self.compute_loss(x, y, y_pred, sample_weight)\n",
      "    File \"/home/hduser/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1139, in compute_loss\n",
      "      return self.compiled_loss(\n",
      "    File \"/home/hduser/.local/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 265, in __call__\n",
      "      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
      "    File \"/home/hduser/.local/lib/python3.10/site-packages/keras/src/losses.py\", line 142, in __call__\n",
      "      losses = call_fn(y_true, y_pred)\n",
      "    File \"/home/hduser/.local/lib/python3.10/site-packages/keras/src/losses.py\", line 268, in call\n",
      "      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
      "    File \"/home/hduser/.local/lib/python3.10/site-packages/keras/src/losses.py\", line 2354, in sparse_categorical_crossentropy\n",
      "      return backend.sparse_categorical_crossentropy(\n",
      "    File \"/home/hduser/.local/lib/python3.10/site-packages/keras/src/backend.py\", line 5762, in sparse_categorical_crossentropy\n",
      "      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
      "Node: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\n",
      "Received a label value of 3 which is outside the valid range of [0, 3).  Label values: 1 2 3 3 3 3 1 1 2 3 1 2\n",
      "\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_1231]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    image_paths =[]\n",
    "    for root, dirs, files in os.walk(file_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.jpg'):\n",
    "                image_paths.append(os.path.join(root, file))\n",
    "                \n",
    "                \n",
    "    split_index = len(image_paths) //2\n",
    "    image_paths_1, image_paths_2 = image_paths[:split_index], image_paths[split_index:]\n",
    "    \n",
    "    with Pool(2) as pool:\n",
    "        data_labels_1 = pool.map(process_image, image_paths_1)\n",
    "        data_labels_2 = pool.map(process_image, image_paths_2)\n",
    "        \n",
    "    data_1, labels_1 = zip(*data_labels_1)\n",
    "    data_2, labels_2 = zip(*data_labels_2)\n",
    "        \n",
    "    data_1, labels_1 = np.array(data_1), np.array(labels_1)\n",
    "    data_2, labels_2 = np.array(data_2), np.array(labels_2)\n",
    "        \n",
    "    process1 = Process(target = train_model, args =(data_1, labels_1))\n",
    "    process2 = Process(target = train_model, args =(data_2, labels_2))\n",
    "        \n",
    "    process1.start()\n",
    "    process2.start()\n",
    "        \n",
    "    process1.join()\n",
    "    process2.join()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a08080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8396e1fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b9986d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a326a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fe890d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e56699",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = []\n",
    "for root, dirs, files in os.walk(file_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.jpg'):\n",
    "            image_paths.append(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba44b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index = len(image_paths) // 2\n",
    "image_paths_1, image_paths_2 = image_paths[:split_index], image_paths[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd2a538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from multiprocessing import Pool\n",
    "with Pool(2) as pool:\n",
    "    data_labels_1 = pool.map(process_image, image_paths_1)\n",
    "    data_labels_2 = pool.map(process_image, image_paths_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c6ca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1, labels_1 = zip(*data_labels_1)\n",
    "data_2, labels_2 = zip(*data_labels_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b58137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_1, labels_1 = np.array(data_1), np.array(labels_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d264d64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_2, labels_2 = np.array(data_2), np.array(labels_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a26755",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labels_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7a0c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287fb03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b583a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649e0270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe692d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249d637f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae79bffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64189de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a716bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a9f4ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9473460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7973adab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b09669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521b50c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b946e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91480cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "for root, dirs, files in os.walk(file_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.jpg'):\n",
    "            image_path = os.path.join(root, file)\n",
    "            label = get_label(file[0])\n",
    "            \n",
    "            \n",
    "            img = cv2.imread(image_path)\n",
    "            img = cv2.resize(img, (img_width, img_height))\n",
    "            \n",
    "            \n",
    "            data.append(img)\n",
    "            labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcde6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a08be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "labels = np.array(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae4a392",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = np.array(data, dtype = 'float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d44fea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb976db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532f8ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdaa34a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05f794e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc8bff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa561134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c212389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96324674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a457d4b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67496c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65132bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ac87a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65ed681",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_hight, target_width = 540, 960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c523dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale = 1.0/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30b7113",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_paths = []\n",
    "y = []\n",
    "\n",
    "for class_name in os.listdir(file_path):\n",
    "    class_path = os.path.join(file_path, class_name)\n",
    "    \n",
    "    if os.path.isdir(class_path):\n",
    "        if class_name.startswith('G'):\n",
    "            label = 0\n",
    "        elif class_name.startswith('Y'):\n",
    "            label = 1\n",
    "        elif class_name.startswith('R'):\n",
    "            label = 2\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        for image_name in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_name)\n",
    "            if image_name.endswith('.jpg'):\n",
    "                image = load_and_preprocess_image(image_path)\n",
    "                x_paths.append(image_path)\n",
    "                y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cc8008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ac7575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc84fd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(file_path):\n",
    "    image = cv2.imread(file_path)\n",
    "    \n",
    "    image = cv2.resize(image, (960,540))\n",
    "    \n",
    "    image = image.astype(np.float32)/255.0\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fe1dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for class_name in os.listdir(file_path):\n",
    "    class_path = os.path.join(file_path, class_name)\n",
    "    \n",
    "    if os.path.isdir(class_path):\n",
    "        if class_name.startswith('G'):\n",
    "            label = 0\n",
    "        elif class_name.startswith('Y'):\n",
    "            label = 1\n",
    "        elif class_name.startswith('R'):\n",
    "            label = 2\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        for image_name in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_name)\n",
    "            if image_name.endswith('.jpg'):\n",
    "                image = load_and_preprocess_image(image_path)\n",
    "                image_paths.append(image_path)\n",
    "                labels.append(label)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcb02f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "\n",
    "for image_path in image_paths:\n",
    "    image = tf.keras.preprocessing.image.load_img(image_path)\n",
    "    image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "   # image = datagen.standarize(image)\n",
    "    X.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b830c8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35bbad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.convert_to_tensor(X)\n",
    "y = tf.convert_to_tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d80a9c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc127f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(image_paths, labels, test_size =0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301cadc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32c561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =[]\n",
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22884c30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da01acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_devices =2\n",
    "num_samples = len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e2927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_per_device = num_samples // num_devices\n",
    "data_subsets = [(X_train[i:i+batch_size_per_device], y_train[i:i+batch_size_per_device]) for i in range(0, num_samples, batch_size_per_device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee1a70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3,3), activation ='relu', input_shape = (32,32,3)),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation ='relu'),\n",
    "        layers.Dense(10, activation ='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer = 'adam',\n",
    "                 loss ='sparse_categorical_crossentropy',\n",
    "                 metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c03a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list =[create_model() for _ in range(num_devices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a7717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_list = tf.keras.optimizers.SGD(learning_rate =0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa9000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs =10\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(num_devices):\n",
    "        x_batch, y_batch = data_subsets[i]\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = models_list[i](x_batch)\n",
    "            loss = tf.keras.losses.sparse_categorical_crossentropy(y_batch, predictions)\n",
    "            \n",
    "        gradients = tape.gradient(loss, models_list[i].trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients,  odels_list[i].trainable_variables))\n",
    "        \n",
    "        \n",
    "    for i in range(1, num_devices):\n",
    "        models_list[i].set_weights(models_list[0].get_weights())\n",
    "        \n",
    "final_model = model_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f79387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857f17e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f1217c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9663978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839524e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9f5014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f952d7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b3f1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e20e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb10d1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf68d02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(540,960,3)),\n",
    "    keras.layers.MaxPooling2D((2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation ='relu'),\n",
    "    keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_cetegorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "X_train_paths = X_train\n",
    "X_train_pixels = np.array([load_and_preprocess_image(image_path) for image_path in X_train_paths])\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_val_paths = X_val\n",
    "X_val_pixels = np.array([load_and_preprocess_image(image_path) for image_path in X_val_paths])\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 10\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_pixels,\n",
    "    y_train,\n",
    "    epochs = epochs,\n",
    "    batch_size = batch_size,\n",
    "    validation_data = (X_val_pixels, y_val)\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Time taken: {elapsed_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5365c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
